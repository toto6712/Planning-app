import openai
import json
import logging
import os
import asyncio
from typing import List, Dict, Any
from models import Intervention, Intervenant, PlanningEvent
from utils.planning_validator import planning_validator
from utils.travel_cache_service import travel_cache_service
from pathlib import Path

logger = logging.getLogger(__name__)

class OpenAIClient:
    def __init__(self):
        # Charger l'environnement
        from dotenv import load_dotenv
        ROOT_DIR = Path(__file__).parent.parent
        load_dotenv(ROOT_DIR / '.env')
        
        api_key = os.getenv('OPENAI_API_KEY')
        if not api_key:
            raise ValueError("OPENAI_API_KEY non trouvÃ©e dans l'environnement")
            
        self.client = openai.OpenAI(api_key=api_key)
        
        # Charger le prompt depuis le fichier
        prompt_path = ROOT_DIR / 'ia_prompt.txt'
        with open(prompt_path, 'r', encoding='utf-8') as f:
            self.system_prompt = f.read()

    async def get_travel_times_with_cache(self, interventions: List[Intervention], intervenants: List[Intervenant]) -> Dict[str, Dict[str, int]]:
        """RÃ©cupÃ¨re les temps de trajet avec calcul automatique des manquants"""
        import time
        start_time = time.time()
        
        logger.info("ðŸ—‚ï¸ === DÃ‰BUT RÃ‰CUPÃ‰RATION TEMPS DE TRAJET ===")
        
        # Collecter TOUTES les coordonnÃ©es
        logger.info("ðŸ”„ Collecte des coordonnÃ©es...")
        all_coordinates = set()
        
        # CoordonnÃ©es des intervenants
        for i, intervenant in enumerate(intervenants, 1):
            all_coordinates.add((intervenant.latitude, intervenant.longitude))
            logger.debug(f"   Intervenant {i}/{len(intervenants)}: {intervenant.nom_prenom} -> ({intervenant.latitude:.4f},{intervenant.longitude:.4f})")
        
        # CoordonnÃ©es des interventions
        for i, intervention in enumerate(interventions, 1):
            all_coordinates.add((intervention.latitude, intervention.longitude))
            logger.debug(f"   Intervention {i}/{len(interventions)}: {intervention.client} -> ({intervention.latitude:.4f},{intervention.longitude:.4f})")
        
        total_coords = len(all_coordinates)
        max_possible_routes = total_coords * (total_coords - 1)
        logger.info(f"ðŸ“ CoordonnÃ©es collectÃ©es: {total_coords} uniques")
        logger.info(f"ðŸ”¢ Trajets thÃ©oriques maximum: {max_possible_routes}")
        
        # Calcul automatique des trajets manquants
        logger.info("ðŸ”„ VÃ©rification du cache et calcul des trajets manquants...")
        calculation_start = time.time()
        calculated_count = await travel_cache_service.calculate_and_cache_missing_routes(all_coordinates)
        calculation_time = time.time() - calculation_start
        
        if calculated_count > 0:
            logger.info(f"âš¡ Performance: {calculated_count} trajets calculÃ©s en {calculation_time:.2f}s")
            logger.info(f"ðŸ“Š Vitesse: {calculated_count/calculation_time:.1f} trajets/seconde")
        else:
            logger.info(f"âœ… Tous les trajets Ã©taient dÃ©jÃ  en cache")
        
        # RÃ©cupÃ©rer tous les temps de trajet depuis le cache (maintenant complet)
        logger.info("ðŸ”„ RÃ©cupÃ©ration des temps de trajet depuis le cache...")
        travel_times = travel_cache_service.get_cached_travel_times(all_coordinates)
        
        total_time = time.time() - start_time
        actual_routes = sum(len(routes) for routes in travel_times.values())
        
        logger.info(f"âœ… === RÃ‰CUPÃ‰RATION TERMINÃ‰E ===")
        logger.info(f"ðŸ“Š RÃ©sumÃ©:")
        logger.info(f"   â€¢ CoordonnÃ©es uniques: {total_coords}")
        logger.info(f"   â€¢ Trajets disponibles: {actual_routes}")
        logger.info(f"   â€¢ Nouveaux calculs: {calculated_count}")
        logger.info(f"   â€¢ Temps total: {total_time:.2f}s")
        return travel_times
        
    async def generate_planning(self, interventions: List[Intervention], intervenants: List[Intervenant]) -> List[PlanningEvent]:
        """GÃ©nÃ¨re un planning optimisÃ© via OpenAI avec calcul automatique des trajets"""
        import time
        total_start_time = time.time()
        
        try:
            logger.info("ðŸš€ === DÃ‰BUT GÃ‰NÃ‰RATION PLANNING IA ===")
            
            # RÃ‰CUPÃ‰RER LES TEMPS DE TRAJET AVEC CALCUL AUTOMATIQUE
            logger.info("ðŸ“ Phase 1/4 - RÃ©cupÃ©ration des temps de trajet")
            travel_times_start = time.time()
            travel_times = await self.get_travel_times_with_cache(interventions, intervenants)
            travel_times_duration = time.time() - travel_times_start
            logger.info(f"âœ… Phase 1/4 terminÃ©e en {travel_times_duration:.2f}s")
            
            # PRÃ‰PARATION DES DONNÃ‰ES POUR L'IA
            logger.info("ðŸ”§ Phase 2/4 - PrÃ©paration des donnÃ©es pour l'IA")
            prep_start = time.time()
            
            # GÃ©nÃ©rer la palette de couleurs pour les intervenants
            color_palette = [
                "#32a852", "#3b82f6", "#f59e0b", "#8b5cf6", "#ef4444", 
                "#06b6d4", "#84cc16", "#f97316", "#ec4899", "#6366f1"
            ]
            
            # CrÃ©er un mapping couleur pour chaque intervenant (en Ã©vitant les doublons)
            intervenant_colors = {}
            noms_uniques = list(set(intervenant.nom_prenom for intervenant in intervenants))
            for i, nom in enumerate(noms_uniques):
                intervenant_colors[nom] = color_palette[i % len(color_palette)]
            
            logger.info(f"ðŸŽ¨ Couleurs assignÃ©es: {len(intervenant_colors)} intervenants")
            
            # PrÃ©parer les donnÃ©es en format compact pour l'IA
            interventions_data = []
            for i, intervention in enumerate(interventions, 1):
                logger.debug(f"   PrÃ©paration intervention {i}/{len(interventions)}: {intervention.client}")
                data = {
                    "client": intervention.client,
                    "date": intervention.date,
                    "duree": intervention.duree,
                    "latitude": intervention.latitude,
                    "longitude": intervention.longitude,
                    "secteur": intervention.secteur
                }
                # N'ajouter l'intervenant que s'il est spÃ©cifiÃ©
                if intervention.intervenant:
                    data["intervenant_impose"] = intervention.intervenant
                # Ajouter les champs spÃ©ciaux
                if intervention.binome:
                    data["binome"] = True
                if intervention.intervenant_referent:
                    data["intervenant_referent"] = intervention.intervenant_referent
                interventions_data.append(data)
            
            intervenants_data = []
            for i, intervenant in enumerate(intervenants, 1):
                logger.debug(f"   PrÃ©paration intervenant {i}/{len(intervenants)}: {intervenant.nom_prenom}")
                data = {
                    "nom_prenom": intervenant.nom_prenom,
                    "latitude": intervenant.latitude,
                    "longitude": intervenant.longitude,
                    "heure_hebdomaire": intervenant.heure_hebdomaire,
                    "heure_mensuel": intervenant.heure_mensuel,
                    "roulement_weekend": intervenant.roulement_weekend,
                    "couleur_assignee": intervenant_colors[intervenant.nom_prenom]
                }
                # Ajouter les champs optionnels
                if intervenant.plage_horaire_autorisee:
                    data["plage_horaire_autorisee"] = intervenant.plage_horaire_autorisee
                if intervenant.specialites:
                    data["specialites"] = intervenant.specialites
                intervenants_data.append(data)
            
            # Construire un message utilisateur compact avec temps de trajet
            user_message = f"""INTERVENTIONS ({len(interventions_data)} total - traiter CHAQUE une EXACTEMENT UNE fois):
{json.dumps(interventions_data, ensure_ascii=False)}

INTERVENANTS ({len(intervenants_data)} total):
{json.dumps(intervenants_data, ensure_ascii=False)}

TEMPS DE TRAJET CALCULÃ‰S (OSRM LOCAL - en minutes) - Format: "latitude,longitude" -> temps:
{json.dumps(travel_times, ensure_ascii=False)}

RÃˆGLES CRITIQUES:
- UTILISER les temps de trajet rÃ©els fournis ci-dessus (format latitude,longitude)
- AUCUN intervenant ne peut Ãªtre Ã  2 endroits en mÃªme temps
- VÃ‰RIFIER les horaires avant assignation
- Temps entre interventions = temps de trajet rÃ©el + 5 min minimum
- Si conflit: chercher autre intervenant ou marquer non_planifiable

RETOURNER {len(interventions_data)} interventions SANS DOUBLONS ni CONFLITS."""
            
            prep_duration = time.time() - prep_start
            logger.info(f"âœ… Phase 2/4 terminÃ©e en {prep_duration:.2f}s")
            logger.info(f"ðŸ“ Taille du message: {len(user_message):,} caractÃ¨res")
            
            # APPEL Ã€ L'IA OPENAI
            logger.info("ðŸ¤– Phase 3/4 - Appel Ã  l'IA OpenAI")
            logger.info(f"ðŸ“¤ Envoi Ã  GPT-4o-mini:")
            logger.info(f"   â€¢ {len(interventions_data)} interventions")
            logger.info(f"   â€¢ {len(intervenants_data)} intervenants") 
            logger.info(f"   â€¢ {sum(len(routes) for routes in travel_times.values())} temps de trajet")
            
            ai_start = time.time()
            # Utiliser GPT-4o-mini qui a des limites plus Ã©levÃ©es
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": self.system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.05,  # TrÃ¨s faible pour cohÃ©rence maximale
                max_tokens=4000
            )
            ai_duration = time.time() - ai_start
            
            # Extraire la rÃ©ponse
            planning_json = response.choices[0].message.content.strip()
            logger.info(f"âœ… Phase 3/4 terminÃ©e en {ai_duration:.2f}s")
            logger.info(f"ðŸ“¥ RÃ©ponse reÃ§ue: {len(planning_json):,} caractÃ¨res")
            
            # TRAITEMENT DE LA RÃ‰PONSE IA
            logger.info("ðŸ” Phase 4/4 - Traitement de la rÃ©ponse IA")
            processing_start = time.time()
            
            # Nettoyer et extraire le JSON
            try:
                # Supprimer les balises markdown si prÃ©sentes
                if "```json" in planning_json:
                    start = planning_json.find("```json") + 7
                    end = planning_json.find("```", start)
                    if end > start:
                        planning_json = planning_json[start:end].strip()
                elif "```" in planning_json:
                    start = planning_json.find("```") + 3
                    end = planning_json.find("```", start)
                    if end > start:
                        planning_json = planning_json[start:end].strip()
                
                # Trouver le JSON array
                start_bracket = planning_json.find("[")
                end_bracket = planning_json.rfind("]")
                
                if start_bracket >= 0 and end_bracket > start_bracket:
                    clean_json = planning_json[start_bracket:end_bracket + 1]
                    logger.info(f"ðŸ§¹ JSON nettoyÃ©: {len(clean_json):,} caractÃ¨res")
                    planning_data = json.loads(clean_json)
                else:
                    # Si pas de crochets trouvÃ©s, essayer de parser directement
                    if planning_json.strip():
                        planning_data = json.loads(planning_json)
                    else:
                        raise ValueError("RÃ©ponse OpenAI vide")
                        
            except json.JSONDecodeError as e:
                logger.error(f"âŒ Erreur parsing JSON OpenAI: {str(e)}")
                logger.error(f"ðŸ“‹ Contenu complet reÃ§u: {planning_json}")
                
                # Tentative de rÃ©cupÃ©ration en cas d'erreur
                if not planning_json.strip():
                    raise ValueError("L'IA n'a pas retournÃ© de rÃ©ponse. RÃ©essayez avec moins d'interventions ou vÃ©rifiez votre clÃ© OpenAI.")
                
                # Essayer de gÃ©nÃ©rer un planning de base en cas d'Ã©chec total
                logger.warning("ðŸ”„ GÃ©nÃ©ration d'un planning de base en cas d'Ã©chec de l'IA")
                planning_data = await self.generate_fallback_planning(interventions, intervenants, travel_times)
                
            except Exception as e:
                logger.error(f"âŒ Erreur inattendue lors du parsing: {str(e)}")
                logger.error(f"ðŸ“‹ RÃ©ponse complÃ¨te: {planning_json}")
                raise ValueError(f"Impossible de traiter la rÃ©ponse de l'IA: {str(e)}")
            
            # VÃ©rifier que planning_data est une liste
            if not isinstance(planning_data, list):
                logger.error(f"âŒ Format de rÃ©ponse invalide: {type(planning_data)}")
                raise ValueError("L'IA n'a pas retournÃ© une liste d'interventions valide")
            
            if not planning_data:
                logger.error("âŒ Liste d'interventions vide retournÃ©e par l'IA")
                raise ValueError("L'IA n'a retournÃ© aucune intervention planifiÃ©e")
            
            # VÃ©rifier que toutes les interventions ont Ã©tÃ© traitÃ©es
            if len(planning_data) != len(interventions_data):
                logger.warning(f"âš ï¸ Nombre d'interventions diffÃ©rent: attendu {len(interventions_data)}, reÃ§u {len(planning_data)}")
            
            # Convertir en objets PlanningEvent
            planning_events = []
            for i, event_data in enumerate(planning_data, 1):
                try:
                    logger.debug(f"   Traitement Ã©vÃ©nement {i}/{len(planning_data)}: {event_data.get('client', 'N/A')}")
                    # VÃ©rifier/corriger la couleur selon l'intervenant
                    intervenant_name = event_data.get('intervenant', '')
                    assigned_color = event_data.get('color', '#64748b')
                    
                    # Si l'intervenant a une couleur assignÃ©e, l'utiliser
                    if intervenant_name in intervenant_colors:
                        assigned_color = intervenant_colors[intervenant_name]
                    
                    event = PlanningEvent(
                        client=event_data.get('client', ''),
                        intervenant=intervenant_name,
                        start=event_data.get('start', ''),
                        end=event_data.get('end', ''),
                        color=assigned_color,
                        non_planifiable=event_data.get('non_planifiable', False),
                        trajet_precedent=event_data.get('trajet_precedent', '0 min'),
                        latitude=event_data.get('latitude', 0.0),
                        longitude=event_data.get('longitude', 0.0),
                        raison=event_data.get('raison', None)
                    )
                    planning_events.append(event)
                except Exception as e:
                    logger.error(f"âŒ Erreur crÃ©ation PlanningEvent {i}: {str(e)}")
                    continue
            
            processing_duration = time.time() - processing_start
            logger.info(f"âœ… Phase 4/4 terminÃ©e en {processing_duration:.2f}s")
            logger.info(f"ðŸ“‹ Planning brut gÃ©nÃ©rÃ©: {len(planning_events)} Ã©vÃ©nements")
            
            # VALIDATION ET CORRECTION DES CONFLITS
            logger.info("ðŸ” Validation finale et correction des conflits...")
            validation_start = time.time()
            validated_planning = planning_validator.validate_and_fix_planning(planning_events)
            validation_duration = time.time() - validation_start
            
            total_duration = time.time() - total_start_time
            
            logger.info(f"âœ… === GÃ‰NÃ‰RATION PLANNING TERMINÃ‰E ===")
            logger.info(f"ðŸ“Š RÃ©sumÃ© complet:")
            logger.info(f"   â€¢ Temps de trajet: {travel_times_duration:.2f}s")
            logger.info(f"   â€¢ PrÃ©paration IA: {prep_duration:.2f}s") 
            logger.info(f"   â€¢ Appel OpenAI: {ai_duration:.2f}s")
            logger.info(f"   â€¢ Traitement: {processing_duration:.2f}s")
            logger.info(f"   â€¢ Validation: {validation_duration:.2f}s")
            logger.info(f"   â€¢ TEMPS TOTAL: {total_duration:.2f}s")
            logger.info(f"   â€¢ Ã‰vÃ©nements finaux: {len(validated_planning)}")
            
            return validated_planning
            
        except openai.APIError as e:
            logger.error(f"Erreur API OpenAI: {str(e)}")
            if "rate_limit_exceeded" in str(e):
                raise ValueError("Limite de tokens OpenAI dÃ©passÃ©e. RÃ©essayez dans 1 minute ou contactez votre administrateur pour augmenter les limites.")
            else:
                raise ValueError(f"Erreur OpenAI: {str(e)}")
        except Exception as e:
            logger.error(f"Erreur gÃ©nÃ©ration planning: {str(e)}")
            raise ValueError(f"Erreur interne: {str(e)}")
    
    async def generate_fallback_planning(self, interventions: List[Intervention], intervenants: List[Intervenant], travel_times: Dict[str, Dict[str, int]]) -> list:
        """GÃ©nÃ¨re un planning de base en cas d'Ã©chec de l'IA"""
        try:
            logger.info("GÃ©nÃ©ration d'un planning de fallback")
            fallback_planning = []
            
            # Couleurs de base
            colors = ["#32a852", "#3b82f6", "#f59e0b", "#8b5cf6", "#ef4444"]
            
            for i, intervention in enumerate(interventions):
                try:
                    # Assigner un intervenant de base
                    intervenant_assigned = intervention.intervenant if intervention.intervenant else (
                        intervenants[i % len(intervenants)].nom_prenom if intervenants else "Non assignÃ©"
                    )
                    
                    # Calculer l'heure de fin (ajouter la durÃ©e Ã  l'heure de dÃ©but)
                    start_time = intervention.date  # Format: "29/06/2025 08:00"
                    duration = intervention.duree   # Format: "01:00"
                    
                    # Convertir au format ISO
                    date_part, time_part = start_time.split(" ")
                    day, month, year = date_part.split("/")
                    start_iso = f"{year}-{month}-{day}T{time_part}"
                    
                    # Calculer l'heure de fin
                    from datetime import datetime, timedelta
                    start_dt = datetime.fromisoformat(start_iso)
                    duration_parts = duration.split(":")
                    duration_td = timedelta(hours=int(duration_parts[0]), minutes=int(duration_parts[1]))
                    end_dt = start_dt + duration_td
                    end_iso = end_dt.isoformat()
                    
                    # Calculer le temps de trajet pour ce fallback
                    trajet_temps = "0 min"
                    if i > 0 and len(fallback_planning) > 0:
                        # Prendre les coordonnÃ©es de la derniÃ¨re intervention
                        prev_lat = fallback_planning[-1]["latitude"]
                        prev_lon = fallback_planning[-1]["longitude"]
                        current_lat = intervention.latitude
                        current_lon = intervention.longitude
                        
                        # Chercher dans le cache des temps de trajet
                        prev_key = f"{prev_lat:.6f},{prev_lon:.6f}"
                        current_key = f"{current_lat:.6f},{current_lon:.6f}"
                        
                        if prev_key in travel_times and current_key in travel_times[prev_key]:
                            trajet_minutes = travel_times[prev_key][current_key]
                            trajet_temps = f"{trajet_minutes} min"
                    
                    fallback_event = {
                        "client": intervention.client,
                        "intervenant": intervenant_assigned,
                        "start": start_iso,
                        "end": end_iso,
                        "color": colors[i % len(colors)],
                        "non_planifiable": False,
                        "trajet_precedent": trajet_temps,
                        "latitude": intervention.latitude,
                        "longitude": intervention.longitude
                    }
                    
                    fallback_planning.append(fallback_event)
                    
                except Exception as e:
                    logger.error(f"Erreur crÃ©ation fallback pour intervention {i}: {str(e)}")
                    continue
            
            logger.info(f"Planning de fallback gÃ©nÃ©rÃ© avec {len(fallback_planning)} interventions")
            return fallback_planning
            
        except Exception as e:
            logger.error(f"Erreur gÃ©nÃ©ration fallback: {str(e)}")
            return []
    
    def calculate_stats(self, planning_events: List[PlanningEvent], total_interventions: int, total_intervenants: int) -> Dict[str, Any]:
        """Calcule las statistiques du planning"""
        try:
            planifiees = sum(1 for event in planning_events if not event.non_planifiable)
            non_planifiables = sum(1 for event in planning_events if event.non_planifiable)
            
            taux_planification = (planifiees / total_interventions * 100) if total_interventions > 0 else 0
            
            return {
                "total_interventions": total_interventions,
                "interventions_planifiees": planifiees,
                "interventions_non_planifiables": non_planifiables,
                "intervenants": total_intervenants,
                "taux_planification": round(taux_planification, 1)
            }
        except Exception as e:
            logger.error(f"Erreur calcul statistiques: {str(e)}")
            return {
                "total_interventions": total_interventions,
                "interventions_planifiees": 0,
                "interventions_non_planifiables": total_interventions,
                "intervenants": total_intervenants,
                "taux_planification": 0.0
            }

# Instance globale du client OpenAI
openai_client = OpenAIClient()